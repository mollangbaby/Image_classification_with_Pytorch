{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRW-dj0qjrhM"
      },
      "source": [
        "# unzip "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjPggi6OkEsj",
        "outputId": "2aa84546-aa30-45c5-cef9-67acfd4a4aa4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMrq_JjVMchA"
      },
      "source": [
        "# 시드 고정 , device 설정 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FF_VxS1dmHJ7",
        "outputId": "903989f7-997b-4848-f666-62556900bca5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# device  :  cuda:0\n"
          ]
        }
      ],
      "source": [
        "# settings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import os \n",
        "import glob\n",
        "import random\n",
        "\n",
        "#GPU 설정\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(\"# device  : \", device)\n",
        "seed = 77\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "\n",
        "seed_everything(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWNQQ8l7kVwp"
      },
      "source": [
        "# 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUsZWqup_pq8",
        "outputId": "c65ae131-11fe-455b-e497-d21df372f870"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(33983, 33983)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "train = np.load(\"/content/drive/MyDrive/vision/OCR이미지분류/train_np.npy\", allow_pickle = True)\n",
        "target = np.load(\"/content/drive/MyDrive/vision/OCR이미지분류/target_encoded_np.npy\", allow_pickle = True)\n",
        "len(train), len(target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flUJU_xcj_ef"
      },
      "source": [
        "# google ViT "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmuPhntMPAPO",
        "outputId": "4db3c417-ae02-4278-e097-b02574cf8a17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm\n",
            "  Downloading timm-0.6.12-py3-none-any.whl (549 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 KB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.9/dist-packages (from timm) (1.13.1+cu116)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from timm) (0.14.1+cu116)\n",
            "Collecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from timm) (6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm) (4.65.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm) (3.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm) (2.27.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm) (23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->timm) (8.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision->timm) (1.22.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub->timm) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub->timm) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub->timm) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub->timm) (3.4)\n",
            "Installing collected packages: huggingface-hub, timm\n",
            "Successfully installed huggingface-hub-0.13.3 timm-0.6.12\n"
          ]
        }
      ],
      "source": [
        "!pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Xz3dBLBjkhFp"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import torch\n",
        "import albumentations\n",
        "import albumentations.pytorch  # torch tensor로 변환할 때 필요 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9xVWbi3SP6YR"
      },
      "outputs": [],
      "source": [
        "class Dataset(torch.utils.data.Dataset) :\n",
        "  def __init__(self, transform  , img_path_np, target=None ):\n",
        "    self.imgs = img_path_np \n",
        "    self.target = target\n",
        "    self.transform = transform\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.imgs)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    item = {}\n",
        "    file_path = self.imgs[idx] \n",
        "    img = cv2.imread(file_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  \n",
        "    item['img'] = self.transform(image = img)['image']\n",
        "    item['y'] = self.target[idx]  # len 159\n",
        "    return item\n",
        "\n",
        "# transformer \n",
        "transformer = albumentations.Compose([\n",
        "    albumentations.Normalize(),\n",
        "    albumentations.Resize(height = 224, width = 224),\n",
        "    albumentations.pytorch.transforms.ToTensorV2(),\n",
        "])\n",
        "\n",
        "\n",
        "# transformer oneof > albumentations \n",
        "transform_oneof = albumentations.Compose([\n",
        "    albumentations.Normalize(),\n",
        "    albumentations.Resize(224, 224), \n",
        "    albumentations.OneOf([\n",
        "                          albumentations.MotionBlur(p=1),\n",
        "                          albumentations.OpticalDistortion(p=1),\n",
        "                          albumentations.GaussNoise(p=1)                 \n",
        "    ], p=1),\n",
        "    albumentations.OneOf([\n",
        "                          albumentations.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "                          albumentations.OpticalDistortion(p=1),\n",
        "                          albumentations.GaussNoise(p=1)                 \n",
        "    ], p=1),\n",
        "    albumentations.pytorch.transforms.ToTensorV2(),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "WEUs8P0lk7us"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import timm\n",
        "\n",
        "seed_everything(seed)\n",
        "num_classes = 159\n",
        "VIT = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01kDM_2naY23"
      },
      "source": [
        "# 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ekrLIaYvhpuz"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "def train_loop(dataloader,model,loss_fn,optimizer,device):\n",
        "    epoch_loss = 0 \n",
        "    model.train() \n",
        "    for batch in tqdm(dataloader): \n",
        "        pred = model(batch[\"img\"].to(device))\n",
        "        loss = loss_fn(pred, batch[\"y\"].to(device))   \n",
        "        optimizer.zero_grad() \n",
        "        loss.backward()  \n",
        "        optimizer.step() \n",
        "        \n",
        "        epoch_loss += loss.item() \n",
        "\n",
        "    epoch_loss /= len(dataloader) \n",
        "\n",
        "    return epoch_loss\n",
        "\n",
        "\n",
        "@torch.no_grad() \n",
        "def test_loop(dataloader,model,loss_fn,device): \n",
        "    epoch_loss = 0\n",
        "    model.eval() \n",
        "    \n",
        "    pred_list = []\n",
        "    true_list = []\n",
        "    softmax = torch.nn.Softmax(dim=1) \n",
        "\n",
        "    for batch in tqdm(dataloader):   \n",
        "        pred = model(batch[\"img\"].to(device))\n",
        "        \n",
        "        if batch.get(\"y\") is not None: \n",
        "            loss = loss_fn(pred, batch[\"y\"].to(device))\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "        pred = softmax(pred)\n",
        "        pred = pred.to(\"cpu\").numpy() \n",
        "        true = batch['y'].to('cpu').numpy()\n",
        "\n",
        "        pred_list.append(pred)\n",
        "        true_list.append(true)\n",
        "\n",
        "    epoch_loss /= len(dataloader)\n",
        "\n",
        "    pred = np.concatenate(pred_list) \n",
        "    true = np.concatenate(true_list)\n",
        "    return epoch_loss , pred , true\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_wc4QU6gxYF"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "seed_everything(77)\n",
        "model = VIT.to(device)\n",
        "# model check ===================================================================\n",
        "optimizer = torch.optim.RAdam(model.parameters(), lr = 0.00001)\n",
        "loss_fn = torch.nn.CrossEntropyLoss() \n",
        "train_x, valid_x, train_y, valid_y = train_test_split(train , target, test_size=0.2, random_state=77)\n",
        "\n",
        "data_train = Dataset(transform_oneof, train_x, train_y)\n",
        "data_test = Dataset(transform_oneof, valid_x, valid_y)\n",
        "train_dl = torch.utils.data.DataLoader(data_train, batch_size = 32, shuffle = True)\n",
        "test_dl = torch.utils.data.DataLoader(data_test, batch_size = 32, shuffle = False)\n",
        "\n",
        "best_score = 0\n",
        "patience = 0\n",
        "num_epochs = 20\n",
        "model = VIT.to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train_loop(train_dl, model , loss_fn,optimizer,device)\n",
        "    valid_loss , pred , true = test_loop(test_dl, model , loss_fn,device  )      \n",
        "    pred = np.argmax(pred, axis=1) \n",
        "    score = f1_score(true, pred , average=\"weighted\")\n",
        "    print(f\"train loss {train_loss},  valid loss : {valid_loss} ,  f1-score : {score}\")\n",
        "    patience += 1\n",
        "    if best_score < score:\n",
        "        patience = 0\n",
        "        best_score = score\n",
        "        # path 지정 부탁드릴게용 \n",
        "        torch.save(model.state_dict(), f\"/content/drive/MyDrive/vision/OCR이미지분류/google_base_vit_net_{epoch}.pth\")\n",
        "\n",
        "    if patience == 3:\n",
        "        break\n",
        "\n",
        "    print(f\" Epoch ({epoch}), BEST F1: {best_score}\")\n",
        "    torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bql91MkHBXPP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUApaknGBuP2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
