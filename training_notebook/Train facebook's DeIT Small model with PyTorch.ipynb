{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRW-dj0qjrhM"
      },
      "source": [
        "# unzip "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjPggi6OkEsj",
        "outputId": "6c27f22a-17e7-4fb9-b299-1306fed10ffd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMrq_JjVMchA"
      },
      "source": [
        "# 시드 고정 , device 설정 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FF_VxS1dmHJ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd0015ee-fbe3-48ed-a33d-596929e92cf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# device  :  cuda:0\n"
          ]
        }
      ],
      "source": [
        "# settings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import os \n",
        "import io\n",
        "import json\n",
        "import glob\n",
        "import random\n",
        "\n",
        "#GPU 설정\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(\"# device  : \", device)\n",
        "seed = 77\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "\n",
        "seed_everything(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUsZWqup_pq8"
      },
      "outputs": [],
      "source": [
        "train = np.load(\"/content/drive/MyDrive/vision/OCR이미지분류/train_np.npy\", allow_pickle = True)\n",
        "target = np.load(\"/content/drive/MyDrive/vision/OCR이미지분류/target_encoded_np.npy\", allow_pickle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQ0Wbg0AjCoi"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import cv2\n",
        "import time\n",
        "import torch\n",
        "import torchvision\n",
        "import albumentations\n",
        "import albumentations.pytorch\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flUJU_xcj_ef"
      },
      "source": [
        "# Deit small"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmuPhntMPAPO",
        "outputId": "77ef403d-fa21-4e82-9d98-76838d059b86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.27.2-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m108.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.13.3 tokenizers-0.13.2 transformers-4.27.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1c3lAh6mulc"
      },
      "source": [
        "#### split "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DeiTFeatureExtractor, DeiTForImageClassification, DeiTConfig"
      ],
      "metadata": {
        "id": "ierYgBijnkNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extractor = DeiTFeatureExtractor.from_pretrained('facebook/deit-small-distilled-patch16-224')\n",
        "# config=DeiTConfig('facebook/deit-small-distilled-patch16-224', num_labels = 159)\n",
        "model = DeiTForImageClassification.from_pretrained( 'facebook/deit-small-distilled-patch16-224')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXiafR-AEt5J",
        "outputId": "0b8422af-7815-43a2-b0f0-2c0047aae6a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at facebook/deit-small-distilled-patch16-224 were not used when initializing DeiTForImageClassification: ['distillation_classifier.bias', 'cls_classifier.weight', 'cls_classifier.bias', 'distillation_classifier.weight']\n",
            "- This IS expected if you are initializing DeiTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DeiTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DeiTForImageClassification were not initialized from the model checkpoint at facebook/deit-small-distilled-patch16-224 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.classifier.out_features = 159\n",
        "# (classifier): Linear(in_features=384, out_features=1000, bias=True)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "vLKgHljLFaWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(torch.utils.data.Dataset) :\n",
        "  def __init__(self, img_path_np, target, extractor):\n",
        "    self.imgs = img_path_np \n",
        "    self.target = target\n",
        "    self.extractor  = extractor\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.imgs)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    item = {}\n",
        "    item['img'] =  self.extractor(images= Image.open(self.imgs[idx]).convert('RGB'), return_tensors=\"pt\")\n",
        "    item['y'] = self.target[idx]  # len 159\n",
        "    return item\n",
        "\n",
        "# image collator \n",
        "def collate_fn(examples):\n",
        "  batch = {}\n",
        "  batch['img'] = torch.stack([x['img']['pixel_values'] for x in examples]).squeeze(1)\n",
        "  batch['y'] = torch.tensor([x['y'] for x in examples])\n",
        "  return batch"
      ],
      "metadata": {
        "id": "8moL6s7unpv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = model(batch['img'].to(device))"
      ],
      "metadata": {
        "id": "rn1vV3TGM6vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out.logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6p64ToC-M86u",
        "outputId": "dc93c273-386e-4a66-f3f9-f328cdbb4c77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0957, -2.3004,  0.7848,  ..., -0.9340, -0.5375,  0.7124],\n",
              "        [-0.3853, -1.9808,  0.3197,  ..., -1.3054, -0.5904,  0.4652],\n",
              "        [-0.0579, -1.8611,  0.6316,  ..., -0.4733,  0.1519,  0.5960],\n",
              "        ...,\n",
              "        [-0.6393, -1.8311, -0.3287,  ..., -0.8843,  0.0606,  0.9284],\n",
              "        [-0.7407, -1.3543,  0.5581,  ..., -0.3060,  0.1552,  1.0115],\n",
              "        [-0.6301, -1.1083,  0.0331,  ..., -1.0321,  0.0532,  0.7027]],\n",
              "       device='cuda:0', grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch['y']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vG2vR-OBNDez",
        "outputId": "22674ee4-e89d-4058-d95c-cd8ccd2cdfc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn(out.logits, batch['y'].to(device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZKdcaXSNQgf",
        "outputId": "aabcc76f-4e6f-4dca-ae2c-b88d8e3edf9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7.5355, device='cuda:0', grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out.logits.to('cpu').detach().numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBKJ4zwE9Z7r",
        "outputId": "2632947d-bb36-4785-b455-283dd68b73bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.09567678, -2.3003726 ,  0.78476584, ..., -0.9339962 ,\n",
              "        -0.53754973,  0.71244264],\n",
              "       [-0.3853176 , -1.9807636 ,  0.31971675, ..., -1.3054347 ,\n",
              "        -0.59040964,  0.46519154],\n",
              "       [-0.05787805, -1.8611178 ,  0.6315767 , ..., -0.47331834,\n",
              "         0.15185937,  0.59603596],\n",
              "       ...,\n",
              "       [-0.6392666 , -1.8310747 , -0.32872403, ..., -0.8843302 ,\n",
              "         0.06060824,  0.92842394],\n",
              "       [-0.74071485, -1.3542597 ,  0.5580878 , ..., -0.30599433,\n",
              "         0.15523499,  1.0114641 ],\n",
              "       [-0.630101  , -1.108257  ,  0.03310081, ..., -1.0321112 ,\n",
              "         0.05321133,  0.70274216]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch['y'].to('cpu').numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7C_dt-u9myc",
        "outputId": "b8d24a5a-a9fb-4946-9553-c625a5bc3535"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01kDM_2naY23"
      },
      "source": [
        "# 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekrLIaYvhpuz"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader,model,loss_fn,optimizer,device):\n",
        "    epoch_loss = 0 \n",
        "    model.train() \n",
        "    for batch in tqdm(dataloader): \n",
        "        pred = model(batch[\"img\"].to(device))\n",
        "        loss = loss_fn(pred.logits, batch[\"y\"].to(device))   \n",
        "        optimizer.zero_grad() \n",
        "        loss.backward()  \n",
        "        optimizer.step() \n",
        "        \n",
        "        epoch_loss += loss.item() \n",
        "\n",
        "    epoch_loss /= len(dataloader) \n",
        "\n",
        "    return epoch_loss\n",
        "\n",
        "\n",
        "@torch.no_grad() \n",
        "def test_loop(dataloader,model,loss_fn,device): \n",
        "    epoch_loss = 0\n",
        "    model.eval() \n",
        "    \n",
        "    pred_list = []\n",
        "    true_list = []\n",
        "    softmax = torch.nn.Softmax(dim=1) \n",
        "\n",
        "    for batch in tqdm(dataloader):   \n",
        "        pred = model(batch[\"img\"].to(device))\n",
        "        pred = pred.logits\n",
        "        \n",
        "        if batch.get(\"y\") is not None: \n",
        "            loss = loss_fn(pred, batch[\"y\"].to(device))\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "        pred = softmax(pred)\n",
        "        pred = pred.to(\"cpu\").detach().numpy() \n",
        "        true = batch['y'].to('cpu').numpy()\n",
        "\n",
        "        pred_list.append(pred)\n",
        "        true_list.append(true)\n",
        "\n",
        "    epoch_loss /= len(dataloader)\n",
        "\n",
        "    pred = np.concatenate(pred_list) \n",
        "    true = np.concatenate(true_list)\n",
        "    return epoch_loss , pred , true\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmJGhNC1iLra"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm_notebook\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import KFold\n",
        "cv = KFold(n_splits=3,shuffle=True, random_state=77)\n",
        "seed_everything(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_wc4QU6gxYF",
        "outputId": "8fc801d6-9b4c-4d8b-f747-6caae901ff3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1416/1416 [17:17<00:00,  1.36it/s]\n",
            "100%|██████████| 708/708 [1:34:56<00:00,  8.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 1.9078346600303542,  valid loss : 1.634409505684497 ,  f1-score : 0.6783617044885011\n",
            " Epoch (0), BEST F1: 0.6783617044885011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1416/1416 [16:33<00:00,  1.43it/s]\n",
            "100%|██████████| 708/708 [07:29<00:00,  1.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 1.155202530745396,  valid loss : 1.0389864811894751 ,  f1-score : 0.7967125220408797\n",
            " Epoch (1), BEST F1: 0.7967125220408797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1416/1416 [16:08<00:00,  1.46it/s]\n",
            "100%|██████████| 708/708 [07:17<00:00,  1.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.6426801791383048,  valid loss : 0.7165520149283111 ,  f1-score : 0.8503890576270104\n",
            " Epoch (2), BEST F1: 0.8503890576270104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1416/1416 [15:56<00:00,  1.48it/s]\n",
            "100%|██████████| 708/708 [07:18<00:00,  1.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.34885656462171993,  valid loss : 0.5475064124556858 ,  f1-score : 0.8755369785474875\n",
            " Epoch (3), BEST F1: 0.8755369785474875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1416/1416 [15:58<00:00,  1.48it/s]\n",
            "100%|██████████| 708/708 [07:21<00:00,  1.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.183169774440154,  valid loss : 0.47189881875953177 ,  f1-score : 0.8888618418711446\n",
            " Epoch (4), BEST F1: 0.8888618418711446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1416/1416 [16:11<00:00,  1.46it/s]\n",
            "100%|██████████| 708/708 [07:17<00:00,  1.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.09676466222410485,  valid loss : 0.40669494751369906 ,  f1-score : 0.8962817371405379\n",
            " Epoch (5), BEST F1: 0.8962817371405379\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1416/1416 [15:56<00:00,  1.48it/s]\n",
            "100%|██████████| 708/708 [07:08<00:00,  1.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.05739063497088155,  valid loss : 0.3961471176556953 ,  f1-score : 0.8974159326764569\n",
            " Epoch (6), BEST F1: 0.8974159326764569\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1416/1416 [15:50<00:00,  1.49it/s]\n",
            "100%|██████████| 708/708 [07:09<00:00,  1.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.04340533082147187,  valid loss : 0.3728456742194018 ,  f1-score : 0.9014249679689155\n",
            " Epoch (7), BEST F1: 0.9014249679689155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1416/1416 [15:52<00:00,  1.49it/s]\n",
            "100%|██████████| 708/708 [07:09<00:00,  1.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.03176599276093582,  valid loss : 0.33450330716510446 ,  f1-score : 0.9100193969890714\n",
            " Epoch (8), BEST F1: 0.9100193969890714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1416/1416 [15:52<00:00,  1.49it/s]\n",
            "100%|██████████| 708/708 [07:12<00:00,  1.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.04431139322794911,  valid loss : 0.31774644840556054 ,  f1-score : 0.913931911300326\n",
            " Epoch (9), BEST F1: 0.913931911300326\n",
            "Fold (0), BEST F1: 0.913931911300326\n"
          ]
        }
      ],
      "source": [
        "seed_everything(77)\n",
        "\n",
        "# model check ===================================================================\n",
        "optimizer = torch.optim.RAdam(model.parameters(), lr = 0.00001)\n",
        "loss_fn = torch.nn.CrossEntropyLoss() \n",
        "batch_size = 16\n",
        "\n",
        "for i,(tri,vai) in enumerate(cv.split(train)):\n",
        "  if i == 0 : \n",
        "      model = model.to(device)\n",
        "      optimizer = torch.optim.RAdam(model.parameters(),lr=0.00001)\n",
        "      train_dt = Dataset(train[tri],target[tri], extractor)\n",
        "      valid_dt = Dataset(train[vai],target[vai], extractor)\n",
        "      train_dl = torch.utils.data.DataLoader(train_dt, batch_size=batch_size, shuffle=True, collate_fn = collate_fn)\n",
        "      valid_dl = torch.utils.data.DataLoader(valid_dt, batch_size=batch_size,shuffle=False, collate_fn = collate_fn)\n",
        "\n",
        "\n",
        "      best_score = 0\n",
        "      patience = 0\n",
        "      best_score_list = []\n",
        "      num_epochs = 10\n",
        "      for epoch in range(num_epochs):\n",
        "          train_loss = train_loop(train_dl, model , loss_fn, optimizer, device)\n",
        "          valid_loss , pred , true = test_loop(valid_dl, model , loss_fn,device  )      \n",
        "          pred = np.argmax(pred, axis=1) \n",
        "          score = f1_score(true, pred , average=\"weighted\")\n",
        "          print(f\"train loss {train_loss},  valid loss : {valid_loss} ,  f1-score : {score}\")\n",
        "          patience += 1\n",
        "          if best_score < score:\n",
        "              patience = 0 \n",
        "              best_score = score\n",
        "              torch.save(model.state_dict(), f\"/content/drive/MyDrive/vision/OCR이미지분류/face_book_Levit_fold_{i}_epoch_{epoch}.pth\")\n",
        "\n",
        "          if patience == 3:\n",
        "              break\n",
        "          print(f\" Epoch ({epoch}), BEST F1: {best_score}\")\n",
        "\n",
        "      print(f\"Fold ({i}), BEST F1: {best_score}\")\n",
        "      torch.cuda.empty_cache()\n",
        "      \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bql91MkHBXPP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUApaknGBuP2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}